{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "eFSKRkc_rtwt",
    "outputId": "74c35034-37c1-4824-ee0d-703f956a315c"
   },
   "outputs": [],
   "source": [
    "# Sets the path based on the environment being used\n",
    "\n",
    "def get_path(computer_str):\n",
    "    \"\"\"\n",
    "    Returns the correct path based on where the program is run\n",
    "    \"\"\"\n",
    "\n",
    "    mac_data_path = '/Users/justinwhatley/Dropbox/FevensLab'\n",
    "    linux_data_path = '/home/justin/Dropbox/FevensLab'\n",
    "    \n",
    "    if computer_str.lower() == 'mac':\n",
    "        return os.path.join(mac_data_path)\n",
    "\n",
    "    elif computer_str.lower() == 'linux': \n",
    "        return os.path.join(linux_data_path)\n",
    "\n",
    "    elif computer_str.lower() == 'colab':\n",
    "        # Google colab path\n",
    "        return os.path.join('')\n",
    "\n",
    "    else: \n",
    "        print('Incorrect base path option')\n",
    "        exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yCvEVe5Go6nH"
   },
   "source": [
    "Separates dataset into folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6OoO2f7Xs6W9"
   },
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "xhklMauLsalV",
    "outputId": "41265bec-9e69-4f25-9e65-513ea653eb18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data from path: /home/justin/Dropbox/FevensLab/FNAB_raw\n",
      "Bin size: 4476\n",
      "Bin size: 4266\n",
      "Bin size: 4494\n",
      "Bin size: 4308\n",
      "Bin size: 4560\n",
      "Bin size: 977\n",
      "Bin size: 1022\n",
      "Bin size: 729\n",
      "Bin size: 1016\n",
      "Bin size: 732\n",
      "Bin size: 94\n",
      "Bin size: 96\n",
      "Bin size: 91\n",
      "Bin size: 92\n",
      "Bin size: 95\n",
      "Bin size: 20\n",
      "Bin size: 26\n",
      "Bin size: 20\n",
      "Bin size: 20\n",
      "Bin size: 20\n",
      "Removing directory: /home/justin/Dropbox/FevensLab/training_validation_dataset\n",
      "Taking files from input directory: /home/justin/Dropbox/FevensLab/FNAB_preprocessed/original_data/MG2\n",
      "Storing them in output directory: /home/justin/Dropbox/FevensLab/training_validation_dataset/original_data/training/MG2\n",
      "Taking files from input directory: /home/justin/Dropbox/FevensLab/FNAB_preprocessed/original_data/MG2\n",
      "Storing them in output directory: /home/justin/Dropbox/FevensLab/training_validation_dataset/original_data/validation/MG2\n",
      "Taking files from input directory: /home/justin/Dropbox/FevensLab/FNAB_preprocessed/original_data/MG3\n",
      "Storing them in output directory: /home/justin/Dropbox/FevensLab/training_validation_dataset/original_data/training/MG3\n",
      "Taking files from input directory: /home/justin/Dropbox/FevensLab/FNAB_preprocessed/original_data/MG3\n",
      "Storing them in output directory: /home/justin/Dropbox/FevensLab/training_validation_dataset/original_data/validation/MG3\n",
      "Finished! \n"
     ]
    }
   ],
   "source": [
    "!rm -rf training_validation_dataset/\n",
    "\n",
    "base_directory = get_path('linux')\n",
    "raw_data_directory_path = os.path.join(base_directory, 'FNAB_raw')\n",
    "preprocessed_directory_path = os.path.join(base_directory, 'FNAB_preprocessed')\n",
    "training_validation_path = os.path.join(base_directory, 'training_validation_dataset')\n",
    "\n",
    "class_keyword_1 = 'MG2'\n",
    "class_keyword_2 = 'MG3'\n",
    "classes_list = [class_keyword_1, class_keyword_2]\n",
    "\n",
    "# Prepares data\n",
    "height, width = 224, 224\n",
    "\n",
    "files_list_by_class = preprocessing.get_raw_file_list(raw_data_directory_path, classes_list)\n",
    "preprocessing.create_preprocessed_directory(classes_list, files_list_by_class, preprocessed_directory_path, height, width, overwrite_previous_preprocessed_data = False)\n",
    "\n",
    "# Gets patch file data\n",
    "patched_class_file_list = preprocessing.get_data_by_class(os.path.join(preprocessed_directory_path, 'patched_data'), classes_list)\n",
    "original_class_file_list = preprocessing.get_data_by_class(os.path.join(preprocessed_directory_path, 'original_data'), classes_list)\n",
    "\n",
    "# Separate data into k-folds\n",
    "number_of_folds = 5\n",
    "files_per_fold =  [4000, 700]\n",
    "patched_files_in_folds = preprocessing.separate_into_k_folds(number_of_folds, patched_class_file_list, files_per_fold)\n",
    "# print(patched_files_in_folds)\n",
    "\n",
    "files_per_fold =  [90, 20]\n",
    "original_files_in_folds = preprocessing.separate_into_k_folds(number_of_folds, original_class_file_list, files_per_fold)\n",
    "# print(original_files_in_folds)\n",
    "\n",
    "# Iterates through folds\n",
    "\n",
    "for i in range(number_of_folds):   \n",
    "    validation_fold = i\n",
    "    \n",
    "    # Removes previous training and validation directories\n",
    "    preprocessing.remove_dir(training_validation_path)\n",
    "                                       \n",
    "    # Selects a validation and training set on the original data\n",
    "    preprocessing.assign_folds_to_training_and_validation(preprocessed_directory_path, training_validation_path, classes_list, original_files_in_folds, validation_fold, type = 'original_data')\n",
    "\n",
    "    # Selects a validation and training set on the patched data\n",
    "#     preprocessing.assign_folds_to_training_and_validation(preprocessed_directory_path, training_validation_path, classes_list, patched_files_in_folds, validation_fold, type = 'patched_data')\n",
    "\n",
    "    # TODO call training and validation from here\n",
    "    print('Finished! ')\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tEGqRMFLBhky"
   },
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WRCXDARNNs2u"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import os.path as path\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9KltowymNR5u"
   },
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "\n",
    "# Dimensions images will be resized to for processing\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "class_list = ['MG2', 'MG3']\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Yz2JBxyoNW3W",
    "outputId": "a44b3b68-1534-4434-a859-aa8f1339d009"
   },
   "outputs": [],
   "source": [
    "\"\"\" Calculates the number of training and validation samples\"\"\"\n",
    "# dataset_name = 'training_validation_dataset/patched_data'\n",
    "\n",
    "# Loads the unaltered images that have been place in training and validation datasets \n",
    "# dataset_name = os.path.join(training_validation_path, 'patched_data')\n",
    "dataset_name = os.path.join(training_validation_path, 'original_data')\n",
    "train_data_dir = path.join(dataset_name, 'training')\n",
    "validation_data_dir = path.join(dataset_name, 'validation')\n",
    "\n",
    "# Calculate number of files in directory \n",
    "import os\n",
    "import glob\n",
    "\n",
    "def get_file_list(path_regex):\n",
    "    file_list = []\n",
    "    for filename in glob.glob(path_regex): \n",
    "        file_list.append(filename)\n",
    "    return file_list\n",
    "  \n",
    "# Loads jpg files using regex\n",
    "# path_regex = path.join(train_data_dir + '/*/*')\n",
    "# nb_train_samples = len(get_file_list(path_regex))\n",
    "# print('Number of training samples: '+ str(nb_train_samples))\n",
    "\n",
    "# path_regex = path.join(validation_data_dir + '/*/*')\n",
    "# nb_validation_samples = len(get_file_list(path_regex))\n",
    "# print('Number of validation samples: '+ str(nb_validation_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Defines pretrained VGG\"\"\"\n",
    "\n",
    "vgg16_model = keras.applications.vgg16.VGG16()\n",
    "model = Sequential()\n",
    "# Transfers the layers from the vgg16 model to a new model that can be trained\n",
    "for layer in vgg16_model.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "# Remove the last (output) layer\n",
    "model.layers.pop()\n",
    "\n",
    "# Replace the last layer with two layers for a binary classification\n",
    "model.add(Dense(2, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "opt = optimizers.SGD(lr=0.01, decay=1e-6)\n",
    "model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloading\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_data_dir, \n",
    "                                                         target_size = (img_width, img_height), \n",
    "                                                         classes = class_list )\n",
    "\n",
    "valid_batches = ImageDataGenerator().flow_from_directory(validation_data_dir, \n",
    "                                                         target_size = (img_width, img_height), \n",
    "                                                         classes = class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_batches,\n",
    "                    steps_per_epoch=4, \n",
    "                    validation_data=valid_batches, \n",
    "                    validation_steps=4, \n",
    "                    epochs=20, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EShr1z8SM96G"
   },
   "outputs": [],
   "source": [
    "\"\"\" Defines the model \"\"\"\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laya's first CNN\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), input_shape=input_shape))\n",
    "model.add(Activation(Dense(128, activation='relu')))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1)))\n",
    "model.add(Activation(Dense(128, activation='relu')))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1)))\n",
    "model.add(Activation(Dense(64, activation='relu')))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1)))\n",
    "model.add(Activation(Dense(64, activation='relu')))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1)))\n",
    "model.add(Activation(Dense(32, activation='relu')))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1)))\n",
    "model.add(Activation(Dense(32, activation='relu')))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YgnkP4Ovduj_"
   },
   "outputs": [],
   "source": [
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        \n",
    "history = AccuracyHistory()\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1697
    },
    "colab_type": "code",
    "id": "-MkLNJlEOc-q",
    "outputId": "1b0029b8-1733-4dc2-ae95-c836b263d2b0"
   },
   "outputs": [],
   "source": [
    "\"\"\" Training and validation for regular network \"\"\"\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps= nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6324
    },
    "colab_type": "code",
    "id": "5RwrYbPKf_8j",
    "outputId": "dfe62f88-e0c1-486f-dab2-ec70067fa2a8"
   },
   "outputs": [],
   "source": [
    "ls training_validation_dataset/patched_data/training/MG3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model CNN:  accuracy history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.grid(b=False)\n",
    "# plt.savefig('accuracy.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model CNN:  loss history')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.grid(b=False, )\n",
    "# plt.savefig('loss.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# from google.colab import files\n",
    "# files.download('loss.png')\n",
    "# files.download('accuracy.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fnab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
